# VoxCPM å…¨é‡å¾®è°ƒå®Œæ•´æŒ‡å—

æœ¬æ–‡æ¡£æä¾› VoxCPM æ¨¡å‹å…¨é‡å¾®è°ƒçš„å®Œæ•´æµç¨‹ï¼ŒåŒ…æ‹¬æ•°æ®å‡†å¤‡ã€å¤„ç†å’Œè®­ç»ƒæ­¥éª¤ã€‚

---

## ä¸€ã€æ•°æ®å‡†å¤‡

### 1.1 éŸ³é¢‘ç´ æè¦æ±‚

ç¡®ä¿åŸå§‹éŸ³é¢‘æ»¡è¶³ä»¥ä¸‹è´¨é‡æ ‡å‡†:

- **çº¯å‡€åº¦è¦æ±‚**:æ— èƒŒæ™¯éŸ³ä¹ã€æ— ç¯å¢ƒæ‚éŸ³
- **æ¨èæ¥æº**:YouTube è§†é¢‘/éŸ³é¢‘ç­‰é«˜è´¨é‡èµ„æº
- **æ ¼å¼å»ºè®®**:WAV æ ¼å¼(æ— æŸéŸ³è´¨)

### 1.2 éŸ³é¢‘é¢„å¤„ç†

ä½¿ç”¨ **Capcut** è¿›è¡ŒéŸ³é¢‘æ¸…ç†:

1. å‰ªé™¤ç‰‡å¤´ç‰‡å°¾å«éŸ³ä¹çš„éƒ¨åˆ†
2. å»é™¤ä¸­é—´çš„æ‚éŸ³ç‰‡æ®µ
3. å¯¼å‡ºä¸º WAV æ ¼å¼

### 1.3 è¯­éŸ³è½¬å†™

ä½¿ç”¨ **Parakeet** å·¥å…·å¯¹ WAV éŸ³é¢‘è¿›è¡Œè‡ªåŠ¨è¯­éŸ³è¯†åˆ«(ASR),ç”Ÿæˆ SRT å­—å¹•æ–‡ä»¶ã€‚

---

## äºŒã€SRT å­—å¹•å¤„ç†

### 2.1 å¤„ç†å¹³å°

è®¿é—® [Google AI Studio](https://aistudio.google.com) ä½¿ç”¨ AI è¾…åŠ©å¤„ç†ã€‚

### 2.2 å¤„ç† Prompt

å°†ä»¥ä¸‹ Prompt æä¾›ç»™ AI æ¨¡å‹,å¹¶é™„ä¸ŠåŸå§‹ SRT æ–‡ä»¶:

```
ã€è§’è‰²è®¾å®šã€‘
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ TTS(è¯­éŸ³åˆæˆ)æ•°æ®é›†å¤„ç†ä¸“å®¶,æ“…é•¿è¿›è¡Œé«˜ç²¾åº¦çš„ SFT æ•°æ®å¯¹é½ä¸æ¸…æ´—ã€‚

ã€ä»»åŠ¡ç›®æ ‡ã€‘
æˆ‘å°†æä¾›ä¸€ä»½ç”± ASR(è‡ªåŠ¨è¯­éŸ³è¯†åˆ«)ç”Ÿæˆçš„åŸå§‹ SRT å­—å¹•æ–‡ä»¶ã€‚è¯·ä½ å°†å…¶å¤„ç†ä¸ºé«˜è´¨é‡çš„ SFT è®­ç»ƒæ•°æ®æ¸…å•ã€‚

ã€æ ¸å¿ƒæ‰§è¡Œæ ‡å‡†(å¿…é¡»ä¸¥æ ¼éµå®ˆ)ã€‘

1. æ—¶é—´è½´ç²¾åº¦(æœ€é«˜ä¼˜å…ˆçº§)
   - ä¸¥ç¦ä¿®æ”¹åŸå§‹æ—¶é—´æˆ³çš„ç²¾åº¦!ä¸¥ç¦å››èˆäº”å…¥!
   - åŸå§‹æ•°æ®æ˜¯å¤šå°‘æ¯«ç§’(ä¾‹å¦‚ 00:27:20,960),è¾“å‡ºå¿…é¡»ä¿æŒä¸€è‡´,ä¸å¾—æ”¹ä¸º 00:27:20,000
   - åˆå¹¶æ—¶,æ–°ç‰‡æ®µçš„"å¼€å§‹æ—¶é—´"å–ç¬¬ä¸€å¥çš„å¼€å§‹,"ç»“æŸæ—¶é—´"å–æœ€åä¸€å¥çš„ç»“æŸ

2. æ—¶é•¿æ§åˆ¶(é€‚é…å¤§æ˜¾å­˜)
   - ç›®æ ‡åˆ‡ç‰‡æ—¶é•¿:5-12 ç§’
   - 12 ç§’ä¸ºæ¨èé˜ˆå€¼,æœ€å¤šä¸è¶…è¿‡ 15 ç§’
   - é€šè¿‡åˆå¹¶çŸ­å¥æ¥è¾¾åˆ°æ­¤æ—¶é•¿

3. è¯­ä¹‰å®Œæ•´æ€§(æ ¸å¿ƒé€»è¾‘)
   - è¯­ä¹‰ä¼˜å…ˆçº§ > æ—¶é•¿ä¼˜å…ˆçº§
   - å¿…é¡»ç¡®ä¿å¥å­çš„å®Œæ•´æ€§,ä¸¥ç¦åœ¨åŠå¥è¯(å¦‚é€—å·åã€ä»å¥ä¸­)æˆªæ–­
   - å°†ç ´ç¢çš„ ASR çŸ­å¥åˆå¹¶ä¸ºå®Œæ•´çš„æ„ç¾¤(å®Œæ•´çš„é™ˆè¿°å¥ã€å¤å¥)

4. æ–‡æœ¬æ¸…æ´—ä¸ç²¾ä¿®
   - æ ‡ç‚¹:ä¿®æ”¹æˆ–æ·»åŠ æ­£ç¡®çš„æ ‡ç‚¹ç¬¦å·(é€—å·ã€å¥å·ã€é—®å·ã€å¼•å·ç­‰),è¿™å†³å®šäº†æ¨¡å‹çš„è¯­æ°”å’ŒéŸµå¾‹
   - æ‹¼å†™:ä¿®æ­£æ˜æ˜¾çš„ ASR è¯†åˆ«é”™è¯¯(å•è¯é”™è¯¯ã€æ‹¼å†™é”™è¯¯)
   - æ ¼å¼:ä¿®æ­£è‹±æ–‡çš„å¤§å°å†™è§„èŒƒ(å¥é¦–å¤§å†™ã€ä¸“æœ‰åè¯å¤§å†™)

ã€è¾“å‡ºæ ¼å¼ã€‘
è¯·ç›´æ¥è¾“å‡ºå¤„ç†åçš„ SRT å†…å®¹,æ ¼å¼å¦‚ä¸‹:

1
00:00:00,000 --> 00:00:12,240
[è¿™é‡Œæ˜¯ä¿®æ­£åçš„ã€å®Œæ•´çš„ã€å¸¦æœ‰æ ‡ç‚¹ç¬¦å·çš„æ–‡æœ¬]

2
00:00:13,120 --> 00:00:26,160
[ä¸‹ä¸€æ®µæ–‡æœ¬...]

ã€å¾…å¤„ç†çš„å­—å¹•å†…å®¹å¦‚ä¸‹ã€‘:
[åœ¨æ­¤ç²˜è´´åŸå§‹ SRT å†…å®¹]
```

### 2.3 éŸ³é¢‘åˆ†å‰²

ä½¿ç”¨ `segment_audio.py` è„šæœ¬æ ¹æ®å¤„ç†åçš„ SRT æ–‡ä»¶åˆ†å‰²éŸ³é¢‘:

```python
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
VoxCPM è®­ç»ƒæ•°æ®éŸ³é¢‘åˆ‡åˆ†è„šæœ¬
åŸºäº SRT + Silero VAD ç²¾å‡†åˆ‡åˆ†
"""

import sys
import os
from pathlib import Path
from typing import List, Dict, Tuple, Optional, Any
import json
import subprocess

# ============================================================================
# é…ç½®å¸¸é‡ï¼ˆç”¨æˆ·å¯ä¿®æ”¹ï¼‰
# ============================================================================

# è™šæ‹Ÿç¯å¢ƒé¡¹ç›®è·¯å¾„ï¼ˆç”¨äºç¯å¢ƒæ£€æŸ¥å’Œæ¨¡å‹ä¸‹è½½ï¼‰
VOXCPM_FT_PROJECT_PATH = r"D:\Project\TTS_ASR_Tools\VoxCPM_FT"

# è¦å¤„ç†çš„éŸ³é¢‘å’Œ SRT æ–‡ä»¶ï¼ˆè„šæœ¬æ‰€åœ¨ç›®å½•ä¸‹ï¼‰
AUDIO_FILENAME = "A01.wav"                # éŸ³é¢‘æ–‡ä»¶å
SRT_FILENAME = "A01.srt"        # SRT æ–‡ä»¶å

# VAD å‚æ•°
BUFFER_MS = 100           # SRT æ—¶é—´å®šä½ Bufferï¼ˆå‰åæ‰©å±•æ—¶é•¿ï¼Œå•ä½ï¼šæ¯«ç§’ï¼‰
SILENCE_MS = 200          # å‰åé™éŸ³æ—¶é•¿ï¼ˆå•ä½ï¼šæ¯«ç§’ï¼‰
VAD_THRESHOLD = 0.5       # VAD æ£€æµ‹é˜ˆå€¼ï¼ˆ0-1ï¼Œè¶Šé«˜è¶Šä¸¥æ ¼ï¼‰

# éŸ³é¢‘é‡‡æ ·ç‡è¦æ±‚
REQUIRED_SAMPLE_RATE = 44100  # VoxCPM1.5 è¦æ±‚ 44.1kHz

# ============================================================================
# å·¥å…·å‡½æ•°
# ============================================================================

def clear_screen() -> None:
    """æ¸…å±å‡½æ•°"""
    os.system('cls' if os.name == 'nt' else 'clear')

def get_script_dir() -> Path:
    """è·å–è„šæœ¬æ‰€åœ¨ç›®å½•"""
    return Path(__file__).parent.resolve()

def get_audio_sample_rate(audio_path: Path) -> Optional[int]:
    """
    ä½¿ç”¨ ffprobe è·å–éŸ³é¢‘é‡‡æ ·ç‡

    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„

    Returns:
        int: é‡‡æ ·ç‡ï¼Œå¤±è´¥è¿”å› None

    Raises:
        RuntimeError: å¦‚æœç³»ç»Ÿæœªå®‰è£… ffprobe
    """
    try:
        result = subprocess.run(
            [
                'ffprobe',
                '-v', 'error',
                '-select_streams', 'a:0',
                '-show_entries', 'stream=sample_rate',
                '-of', 'default=noprint_wrappers=1:nokey=1',
                str(audio_path)
            ],
            capture_output=True,
            text=True,
            timeout=10
        )

        if result.returncode == 0 and result.stdout.strip():
            return int(result.stdout.strip())
        else:
            return None

    except FileNotFoundError:
        raise RuntimeError("ç³»ç»Ÿæœªå®‰è£… ffprobeï¼Œæ— æ³•æ£€æŸ¥éŸ³é¢‘é‡‡æ ·ç‡ã€‚è¯·å®‰è£… ffmpeg åé‡è¯•ã€‚")
    except subprocess.TimeoutExpired:
        print(f"  è­¦å‘Šï¼šffprobe æ£€æŸ¥è¶…æ—¶")
        return None
    except Exception as e:
        print(f"  ffprobe æ£€æŸ¥å¤±è´¥ï¼š{e}")
        return None

def get_last_segment_number(jsonl_path: Path) -> int:
    """
    è¯»å– JSONL æ–‡ä»¶ï¼Œè·å–æœ€åä¸€ä¸ªéŸ³é¢‘ç‰‡æ®µçš„åºå·

    Args:
        jsonl_path: JSONL æ–‡ä»¶è·¯å¾„

    Returns:
        int: æœ€åçš„åºå·ï¼Œå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨æˆ–ä¸ºç©ºè¿”å› 0
    """
    if not jsonl_path.exists():
        return 0

    try:
        with open(jsonl_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()

        if not lines:
            return 0

        # è¯»å–æœ€åä¸€è¡Œ
        last_line = lines[-1].strip()
        if not last_line:
            return 0

        data = json.loads(last_line)
        audio_path = Path(data['audio'])
        filename = audio_path.stem  # ä¸å«æ‰©å±•åçš„æ–‡ä»¶å

        # æå–åºå·ï¼ˆå¦‚ "0010" -> 10ï¼‰
        try:
            return int(filename)
        except ValueError:
            print(f"  è­¦å‘Šï¼šæ— æ³•è§£ææ–‡ä»¶åä¸­çš„åºå·ï¼š{filename}ï¼Œä» 0 å¼€å§‹")
            return 0

    except Exception as e:
        print(f"  è­¦å‘Šï¼šè¯»å– JSONL æ–‡ä»¶å¤±è´¥ï¼š{e}ï¼Œä» 0 å¼€å§‹")
        return 0

# ============================================================================
# ç¯å¢ƒæ£€æŸ¥
# ============================================================================

def check_prerequisites() -> bool:
    """æ£€æŸ¥å‰ç½®æ¡ä»¶"""
    script_dir = get_script_dir()

    # æ£€æŸ¥éŸ³é¢‘æ–‡ä»¶
    audio_path = script_dir / AUDIO_FILENAME
    if not audio_path.exists():
        print(f"é”™è¯¯ï¼šéŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨")
        print(f"è·¯å¾„ï¼š{audio_path}")
        print(f"è¯·æ£€æŸ¥é…ç½®å¸¸é‡ AUDIO_FILENAME æ˜¯å¦æ­£ç¡®")
        return False

    # æ£€æŸ¥éŸ³é¢‘é‡‡æ ·ç‡
    print(f"æ£€æŸ¥éŸ³é¢‘é‡‡æ ·ç‡...")
    try:
        sample_rate = get_audio_sample_rate(audio_path)
    except RuntimeError as e:
        print(f"é”™è¯¯ï¼š{e}")
        return False

    if sample_rate is None:
        print(f"é”™è¯¯ï¼šæ— æ³•è·å–éŸ³é¢‘é‡‡æ ·ç‡")
        return False

    if sample_rate != REQUIRED_SAMPLE_RATE:
        print(f"é”™è¯¯ï¼šéŸ³é¢‘é‡‡æ ·ç‡ä¸ç¬¦åˆè¦æ±‚")
        print(f"  å½“å‰é‡‡æ ·ç‡ï¼š{sample_rate} Hz")
        print(f"  è¦æ±‚é‡‡æ ·ç‡ï¼š{REQUIRED_SAMPLE_RATE} Hz")
        print(f"  VoxCPM1.5 å¿…é¡»ä½¿ç”¨ 44.1kHz éŸ³é¢‘")
        print(f"ç¨‹åºç»ˆæ­¢ï¼")
        return False

    print(f"éŸ³é¢‘é‡‡æ ·ç‡æ£€æŸ¥é€šè¿‡ï¼š{sample_rate} Hz âœ“")

    # æ£€æŸ¥ SRT æ–‡ä»¶
    srt_path = script_dir / SRT_FILENAME
    if not srt_path.exists():
        print(f"é”™è¯¯ï¼šSRT æ–‡ä»¶ä¸å­˜åœ¨")
        print(f"è·¯å¾„ï¼š{srt_path}")
        print(f"è¯·æ£€æŸ¥é…ç½®å¸¸é‡ SRT_FILENAME æ˜¯å¦æ­£ç¡®")
        return False

    return True

# ============================================================================
# SRT è§£æ
# ============================================================================

def parse_srt_time(time_str: str) -> float:
    """
    å°† SRT æ—¶é—´æ ¼å¼è½¬æ¢ä¸ºç§’æ•°

    Args:
        time_str: SRT æ—¶é—´æ ¼å¼å­—ç¬¦ä¸²ï¼Œå¦‚ "00:01:23,456"

    Returns:
        float: æ—¶é—´ï¼ˆç§’ï¼‰

    Raises:
        ValueError: å¦‚æœæ—¶é—´æ ¼å¼ä¸æ­£ç¡®
    """
    try:
        time_str = time_str.strip()
        hours, minutes, seconds_ms = time_str.split(':')
        seconds, milliseconds = seconds_ms.split(',')

        total_seconds = (
            int(hours) * 3600 +
            int(minutes) * 60 +
            int(seconds) +
            int(milliseconds) / 1000.0
        )

        return total_seconds
    except (ValueError, IndexError) as e:
        raise ValueError(f"æ— æ•ˆçš„ SRT æ—¶é—´æ ¼å¼ï¼š{time_str}") from e

def parse_srt_file(srt_path: Path) -> List[Dict[str, Any]]:
    """
    è§£æ SRT æ–‡ä»¶

    Args:
        srt_path: SRT æ–‡ä»¶è·¯å¾„

    Returns:
        list: åŒ…å«æ®µè½ä¿¡æ¯çš„åˆ—è¡¨
    """
    segments = []

    with open(srt_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()

    i = 0
    while i < len(lines):
        line = lines[i].strip()

        # è·³è¿‡ç©ºè¡Œ
        if not line:
            i += 1
            continue

        # æ®µè½ç¼–å·
        try:
            segment_num = int(line)
        except ValueError:
            i += 1
            continue

        # æ—¶é—´è½´
        i += 1
        if i >= len(lines):
            break

        time_line = lines[i].strip()
        if '-->' not in time_line:
            continue

        try:
            parts = time_line.split('-->')
            if len(parts) != 2:
                print(f"  è­¦å‘Šï¼šæ®µè½ {segment_num} æ—¶é—´è½´æ ¼å¼é”™è¯¯ï¼Œè·³è¿‡")
                i += 1
                continue

            start_str, end_str = parts
            start_time = parse_srt_time(start_str)
            end_time = parse_srt_time(end_str)
        except ValueError as e:
            print(f"  è­¦å‘Šï¼šæ®µè½ {segment_num} æ—¶é—´è½´è§£æå¤±è´¥ï¼š{e}ï¼Œè·³è¿‡")
            i += 1
            continue

        # æ–‡æœ¬å†…å®¹ï¼ˆå¯èƒ½å¤šè¡Œï¼‰
        i += 1
        text_lines = []
        while i < len(lines) and lines[i].strip():
            text_lines.append(lines[i].strip())
            i += 1

        text = ' '.join(text_lines)

        segments.append({
            'index': segment_num,
            'start': start_time,
            'end': end_time,
            'duration': end_time - start_time,
            'text': text
        })

        i += 1

    return segments

# ============================================================================
# éŸ³é¢‘å¤„ç† - è¾…åŠ©å‡½æ•°
# ============================================================================

def get_duration_with_ffprobe(audio_path: Path) -> float:
    """
    ä½¿ç”¨ ffprobe è·å–éŸ³é¢‘æ–‡ä»¶çš„ç²¾ç¡®æ—¶é•¿

    Args:
        audio_path: éŸ³é¢‘æ–‡ä»¶è·¯å¾„

    Returns:
        float: éŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
    """
    import soundfile as sf

    try:
        result = subprocess.run(
            [
                'ffprobe',
                '-v', 'error',
                '-show_entries', 'format=duration',
                '-of', 'default=noprint_wrappers=1:nokey=1',
                str(audio_path)
            ],
            capture_output=True,
            text=True,
            timeout=10
        )

        if result.returncode == 0 and result.stdout.strip():
            return float(result.stdout.strip())
    except Exception as e:
        print(f"  è­¦å‘Šï¼šffprobe è·å–æ—¶é•¿å¤±è´¥ï¼Œä½¿ç”¨ soundfileï¼š{e}")

    # é™çº§æ–¹æ¡ˆï¼šä½¿ç”¨ soundfile
    audio, sr = sf.read(audio_path)
    return len(audio) / sr

def process_single_segment(
    seg: Dict[str, Any],
    audio: Any,
    sr: int,
    audio_duration: float,
    output_dir: Path,
    current_index: int,
    vad_model: Any,
    get_speech_timestamps: Any,
    resampler: Any,
    target_sr: int,
    buffer_samples: int,
    silence_samples: int
) -> Optional[Tuple[Dict[str, Any], Optional[str]]]:
    """
    å¤„ç†å•ä¸ªéŸ³é¢‘ç‰‡æ®µ

    Args:
        seg: SRT æ®µè½ä¿¡æ¯
        audio: åŸå§‹éŸ³é¢‘æ•°ç»„
        sr: é‡‡æ ·ç‡
        audio_duration: éŸ³é¢‘æ€»æ—¶é•¿
        output_dir: è¾“å‡ºç›®å½•
        current_index: å½“å‰ç‰‡æ®µåºå·
        vad_model: Silero VAD æ¨¡å‹
        get_speech_timestamps: VAD å·¥å…·å‡½æ•°
        resampler: é‡é‡‡æ ·å™¨
        target_sr: ç›®æ ‡é‡‡æ ·ç‡ï¼ˆ16kHzï¼‰
        buffer_samples: Buffer æ ·æœ¬æ•°
        silence_samples: é™éŸ³æ ·æœ¬æ•°

    Returns:
        Optional[Tuple[Dict, Optional[str]]]: (è®­ç»ƒæ•°æ®å­—å…¸, VADè­¦å‘Šä¿¡æ¯) æˆ– Noneï¼ˆå¤±è´¥ï¼‰
    """
    import numpy as np
    import soundfile as sf
    import torch

    srt_start = seg['start']
    srt_end = seg['end']
    text = seg['text']

    # 1. è®¡ç®—æ‰©å±•åçš„æœç´¢åŒºåŸŸï¼ˆåŠ  bufferï¼‰
    search_start_time = max(0, srt_start - BUFFER_MS / 1000)
    search_end_time = min(audio_duration, srt_end + BUFFER_MS / 1000)

    search_start_sample = int(search_start_time * sr)
    search_end_sample = int(search_end_time * sr)

    # æå–æœç´¢åŒºåŸŸ
    search_region = audio[search_start_sample:search_end_sample]

    if len(search_region) == 0:
        print(f"  âš ï¸  æ®µè½ {current_index:04d}: æœç´¢åŒºåŸŸä¸ºç©ºï¼Œè·³è¿‡")
        return None

    # 2. ä½¿ç”¨ Silero VAD åœ¨æœç´¢åŒºåŸŸå†…ç²¾å‡†æ£€æµ‹ï¼ˆ16kHzï¼‰
    vad_warning = None
    try:
        # è½¬æ¢ä¸º torch.Tensor
        search_tensor = torch.from_numpy(search_region.astype(np.float32))

        # é‡é‡‡æ ·åˆ° 16000 Hzï¼ˆä»…ç”¨äº VAD æ£€æµ‹ï¼‰
        search_16k = resampler(search_tensor)

        # VAD æ£€æµ‹
        speech_timestamps = get_speech_timestamps(
            search_16k,
            vad_model,
            sampling_rate=target_sr,
            threshold=VAD_THRESHOLD,
            return_seconds=True
        )

        # 3. ç¡®å®šç²¾å‡†çš„è¯­éŸ³è¾¹ç•Œ
        if speech_timestamps:
            # VAD æ£€æµ‹æˆåŠŸï¼šä½¿ç”¨ç¬¬ä¸€ä¸ªå’Œæœ€åä¸€ä¸ªè¯­éŸ³æ®µ
            first_segment = speech_timestamps[0]
            last_segment = speech_timestamps[-1]

            # è¯­éŸ³åœ¨æœç´¢åŒºåŸŸå†…çš„ç›¸å¯¹ä½ç½®ï¼ˆç§’ï¼‰
            relative_start = first_segment['start']
            relative_end = last_segment['end']

            # è½¬æ¢ä¸ºåŸå§‹éŸ³é¢‘çš„ç»å¯¹ä½ç½®ï¼ˆæ ·æœ¬ç‚¹ï¼Œä¿æŒåŸå§‹ 44.1kHzï¼‰
            absolute_start_sample = search_start_sample + int(relative_start * sr)
            absolute_end_sample = search_start_sample + int(relative_end * sr)

        else:
            # VAD æ£€æµ‹å¤±è´¥ï¼šé€€å›åˆ° SRT æ—¶é—´è½´
            vad_warning = f"æ®µè½ {current_index:04d}: VAD æœªæ£€æµ‹åˆ°è¯­éŸ³ï¼Œä½¿ç”¨ SRT æ—¶é—´è½´"
            absolute_start_sample = int(srt_start * sr)
            absolute_end_sample = int(srt_end * sr)

        # è¾¹ç•Œæ£€æŸ¥
        absolute_start_sample = max(0, absolute_start_sample)
        absolute_end_sample = min(absolute_end_sample, len(audio))

        if absolute_end_sample <= absolute_start_sample:
            print(f"  âš ï¸  æ®µè½ {current_index:04d}: æ— æ•ˆçš„æ—¶é—´èŒƒå›´ï¼Œè·³è¿‡")
            return None

        # 4. æå–ç²¾å‡†çš„è¯­éŸ³å†…å®¹ï¼ˆä¿æŒåŸå§‹ 44.1kHzï¼‰
        audio_content = audio[absolute_start_sample:absolute_end_sample]

        # 5. æ·»åŠ å‰åé™éŸ³
        front_silence = np.zeros(silence_samples, dtype=audio.dtype)
        end_silence = np.zeros(silence_samples, dtype=audio.dtype)
        audio_final = np.concatenate([front_silence, audio_content, end_silence])

        # 6. ä¿å­˜éŸ³é¢‘æ–‡ä»¶
        output_filename = f"{current_index:04d}.wav"
        output_path = output_dir / output_filename
        sf.write(output_path, audio_final, sr)

        # 7. éªŒè¯ä¿å­˜çš„éŸ³é¢‘é‡‡æ ·ç‡
        verify_sr = get_audio_sample_rate(output_path)
        if verify_sr != REQUIRED_SAMPLE_RATE:
            print(f"  âš ï¸  è­¦å‘Šï¼šä¿å­˜çš„éŸ³é¢‘é‡‡æ ·ç‡ä¸æ­£ç¡® ({verify_sr} Hz)")

        # 8. ä½¿ç”¨ ffprobe è·å–ç²¾ç¡® duration
        duration = get_duration_with_ffprobe(output_path)

        # 9. è¿”å›è®­ç»ƒæ•°æ®
        training_item = {
            'audio': str(output_path.absolute()),
            'text': text,
            'duration': round(duration, 2)
        }

        return (training_item, vad_warning)

    except (IOError, ValueError, RuntimeError) as e:
        print(f"  âš ï¸  æ®µè½ {current_index:04d} å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None
    except KeyboardInterrupt:
        print(f"\nç”¨æˆ·ä¸­æ–­å¤„ç†")
        raise

# ============================================================================
# éŸ³é¢‘å¤„ç† - ä¸»å‡½æ•°
# ============================================================================

def segment_audio_with_vad(
    audio_path: Path,
    segments: List[Dict[str, Any]],
    output_dir: Path,
    vad_model: Any,
    get_speech_timestamps: Any,
    start_index: int,
    buffer_ms: int = BUFFER_MS,
    silence_ms: int = SILENCE_MS
) -> Tuple[List[Dict[str, Any]], List[str]]:
    """
    ä½¿ç”¨ Silero VAD ç²¾å‡†åˆ‡åˆ†éŸ³é¢‘

    å¤„ç†æµç¨‹ï¼š
    1. æ ¹æ® SRT æ—¶é—´è½´å¤§è‡´å®šä½ï¼ˆæ‰©å±• bufferï¼‰
    2. åœ¨è¯¥åŒºåŸŸå†…ä½¿ç”¨ VAD ç²¾å‡†æ£€æµ‹è¯­éŸ³è¾¹ç•Œï¼ˆ16kHzï¼‰
    3. æå–ç²¾å‡†çš„è¯­éŸ³å†…å®¹ï¼ˆä¿æŒåŸå§‹ 44.1kHzï¼‰
    4. æ·»åŠ å‰åé™éŸ³
    5. ä¿å­˜å¹¶è·å– duration

    Args:
        audio_path: åŸå§‹éŸ³é¢‘æ–‡ä»¶è·¯å¾„
        segments: SRT æ®µè½åˆ—è¡¨
        output_dir: è¾“å‡ºç›®å½•
        vad_model: Silero VAD æ¨¡å‹
        get_speech_timestamps: VAD å·¥å…·å‡½æ•°
        start_index: èµ·å§‹åºå·
        buffer_ms: SRT æ—¶é—´å®šä½ Bufferï¼ˆæ¯«ç§’ï¼‰
        silence_ms: å‰åé™éŸ³æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰

    Returns:
        tuple: (è®­ç»ƒæ•°æ®åˆ—è¡¨, VAD å¤±è´¥è­¦å‘Šåˆ—è¡¨)
    """
    import numpy as np
    import soundfile as sf
    import torch
    import torchaudio
    from tqdm import tqdm

    # åŠ è½½åŸå§‹éŸ³é¢‘
    print(f"ğŸ“‚ åŠ è½½éŸ³é¢‘: {audio_path.name}")
    audio, sr = sf.read(audio_path)

    # éªŒè¯é‡‡æ ·ç‡
    if sr != REQUIRED_SAMPLE_RATE:
        print(f"  é”™è¯¯ï¼šéŸ³é¢‘é‡‡æ ·ç‡ä¸åŒ¹é…")
        print(f"    æœŸæœ›ï¼š{REQUIRED_SAMPLE_RATE} Hz")
        print(f"    å®é™…ï¼š{sr} Hz")
        sys.exit(1)

    # å¦‚æœæ˜¯ç«‹ä½“å£°ï¼Œè½¬ä¸ºå•å£°é“
    if len(audio.shape) > 1:
        audio = np.mean(audio, axis=1)

    audio_duration = len(audio) / sr
    print(f"âœ… éŸ³é¢‘åŠ è½½æˆåŠŸ - é‡‡æ ·ç‡: {sr} Hz, æ—¶é•¿: {audio_duration:.2f} ç§’")

    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)

    # Silero VAD éœ€è¦ 16000 Hzï¼Œå‡†å¤‡é‡é‡‡æ ·å™¨ï¼ˆä»…ç”¨äº VAD æ£€æµ‹ï¼‰
    target_sr = 16000
    resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=target_sr)

    # å¤„ç†æ•°æ®
    training_data = []
    vad_fallback_warnings = []
    skipped = 0

    buffer_samples = int(buffer_ms / 1000 * sr)
    silence_samples = int(silence_ms / 1000 * sr)

    current_index = start_index

    for seg in tqdm(segments, desc="åˆ‡åˆ†éŸ³é¢‘"):
        current_index += 1

        result = process_single_segment(
            seg=seg,
            audio=audio,
            sr=sr,
            audio_duration=audio_duration,
            output_dir=output_dir,
            current_index=current_index,
            vad_model=vad_model,
            get_speech_timestamps=get_speech_timestamps,
            resampler=resampler,
            target_sr=target_sr,
            buffer_samples=buffer_samples,
            silence_samples=silence_samples
        )

        if result is None:
            skipped += 1
            continue

        training_item, vad_warning = result
        training_data.append(training_item)

        if vad_warning:
            vad_fallback_warnings.append(vad_warning)
            # å®æ—¶åé¦ˆ VAD å¤±è´¥
            tqdm.write(f"  âš ï¸  {vad_warning}")

    print(f"\nâœ… åˆ‡åˆ†å®Œæˆ: {len(training_data)} ä¸ªç‰‡æ®µ")
    if skipped > 0:
        print(f"âš ï¸  è·³è¿‡äº† {skipped} ä¸ªæ— æ•ˆç‰‡æ®µ")

    return training_data, vad_fallback_warnings

# ============================================================================
# ä¸»ç¨‹åº
# ============================================================================

def run_segment_audio() -> None:
    """æ‰§è¡ŒéŸ³é¢‘åˆ‡åˆ†ï¼ˆè‡ªåŠ¨å¯åŠ¨è™šæ‹Ÿç¯å¢ƒï¼‰"""
    # æ£€æŸ¥è™šæ‹Ÿç¯å¢ƒç›®å½•æ˜¯å¦å­˜åœ¨
    voxcpm_ft_path = Path(VOXCPM_FT_PROJECT_PATH)
    if not voxcpm_ft_path.exists():
        print(f"é”™è¯¯ï¼šVoxCPM_FT é¡¹ç›®ç›®å½•ä¸å­˜åœ¨")
        print(f"è·¯å¾„ï¼š{voxcpm_ft_path}")
        print(f"è¯·æ£€æŸ¥é…ç½®å¸¸é‡ VOXCPM_FT_PROJECT_PATH æ˜¯å¦æ­£ç¡®")
        print(f"ç¨‹åºç»ˆæ­¢ï¼")
        sys.exit(1)

    # æ£€æŸ¥è™šæ‹Ÿç¯å¢ƒ Python æ˜¯å¦å­˜åœ¨
    venv_python = voxcpm_ft_path / "runtime" / "Scripts" / "python.exe"
    if not venv_python.exists():
        print(f"é”™è¯¯ï¼šVoxCPM_FT Python è™šæ‹Ÿç¯å¢ƒä¸å­˜åœ¨")
        print(f"è·¯å¾„ï¼š{venv_python}")
        print(f"è¯·ç¡®è®¤è™šæ‹Ÿç¯å¢ƒå·²æ­£ç¡®åˆ›å»º")
        print(f"ç¨‹åºç»ˆæ­¢ï¼")
        sys.exit(1)

    # æ£€æŸ¥å½“å‰ Python ç¯å¢ƒ
    current_python = Path(sys.executable).resolve()

    # å¦‚æœä¸åœ¨è™šæ‹Ÿç¯å¢ƒä¸­ï¼Œè‡ªåŠ¨å¯åŠ¨è™šæ‹Ÿç¯å¢ƒ
    if current_python != venv_python:
        print(f"æ£€æµ‹åˆ°æœªåœ¨è™šæ‹Ÿç¯å¢ƒä¸­è¿è¡Œ")
        print(f"å¯åŠ¨ VoxCPM_FT Python è™šæ‹Ÿç¯å¢ƒ...")
        print()

        # è®¾ç½®ç¯å¢ƒå˜é‡
        env = os.environ.copy()

        # è®¾ç½® Silero VAD æ¨¡å‹ä¸‹è½½ç›®å½•
        models_dir = voxcpm_ft_path / "models"
        models_dir.mkdir(parents=True, exist_ok=True)
        env['TORCH_HOME'] = str(models_dir)

        # ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒçš„ Python é‡æ–°è¿è¡Œæœ¬è„šæœ¬ï¼ˆä¼ é€’æ‰€æœ‰å‘½ä»¤è¡Œå‚æ•°ï¼‰
        result = subprocess.run(
            [str(venv_python), __file__] + sys.argv[1:],
            env=env
        )

        if result.returncode != 0:
            print(f"é”™è¯¯ï¼šéŸ³é¢‘åˆ‡åˆ†è¿›ç¨‹å¼‚å¸¸é€€å‡ºï¼Œè¿”å›ç ï¼š{result.returncode}")
            sys.exit(1)

        # å­è¿›ç¨‹æ‰§è¡Œå®Œæ¯•ï¼Œé€€å‡ºä¸»è¿›ç¨‹
        sys.exit(0)

    # åˆ°è¿™é‡Œè¯´æ˜å·²ç»åœ¨è™šæ‹Ÿç¯å¢ƒä¸­äº†
    print("VoxCPM_FT è™šæ‹Ÿç¯å¢ƒå¯åŠ¨å®Œæ¯• âœ“")
    print()

    # æ‰§è¡Œå®é™…çš„éŸ³é¢‘åˆ‡åˆ†æµç¨‹
    execute_segmentation()

def execute_segmentation() -> None:
    """æ‰§è¡ŒéŸ³é¢‘åˆ‡åˆ†çš„å®é™…é€»è¾‘ï¼ˆåœ¨è™šæ‹Ÿç¯å¢ƒä¸­è¿è¡Œï¼‰"""
    # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•
    script_dir = get_script_dir()

    print(f"ğŸ“ å·¥ä½œç›®å½•: {script_dir}")
    print(f"ğŸ“ è™šæ‹Ÿç¯å¢ƒ: {VOXCPM_FT_PROJECT_PATH}")
    print()

    # æ£€æŸ¥å‰ç½®æ¡ä»¶
    print("æ£€æŸ¥å‰ç½®æ¡ä»¶...")
    if not check_prerequisites():
        sys.exit(1)
    print("å‰ç½®æ¡ä»¶æ£€æŸ¥é€šè¿‡ âœ“")
    print()

    print(f"âš™ï¸  é…ç½®å‚æ•°:")
    print(f"   - éŸ³é¢‘æ–‡ä»¶: {AUDIO_FILENAME}")
    print(f"   - SRT æ–‡ä»¶: {SRT_FILENAME}")
    print(f"   - Buffer æ—¶é•¿: {BUFFER_MS} ms")
    print(f"   - é™éŸ³æ—¶é•¿: {SILENCE_MS} ms (å‰å)")
    print(f"   - VAD é˜ˆå€¼: {VAD_THRESHOLD}")
    print(f"   - é‡‡æ ·ç‡è¦æ±‚: {REQUIRED_SAMPLE_RATE} Hz")
    print()

    # è®¾ç½®è·¯å¾„
    audio_path = script_dir / AUDIO_FILENAME
    srt_path = script_dir / SRT_FILENAME
    data_dir = script_dir / "data"
    jsonl_path = data_dir / "train.jsonl"

    # æ£€æŸ¥è¿½åŠ æ¨¡å¼
    start_index = get_last_segment_number(jsonl_path)
    if start_index > 0:
        print(f"ğŸ“ æ£€æµ‹åˆ°ç°æœ‰è®­ç»ƒæ•°æ®ï¼Œè¿½åŠ æ¨¡å¼å¯åŠ¨")
        print(f"   ä¸Šæ¬¡æœ€ååºå·: {start_index:04d}")
        print(f"   æœ¬æ¬¡èµ·å§‹åºå·: {start_index + 1:04d}")
        print()
    else:
        print(f"ğŸ“ æ–°å»ºè®­ç»ƒæ•°æ®ï¼Œä»åºå· 0001 å¼€å§‹")
        print()

    # å¯¼å…¥ä¾èµ–
    print("-" * 60)
    print("å¯¼å…¥ä¾èµ–åº“...")
    try:
        import torch
        import torchaudio
        import numpy as np
        import soundfile as sf
        from tqdm import tqdm
    except ImportError as e:
        print(f"é”™è¯¯ï¼šç¼ºå°‘å¿…è¦çš„åº“ - {e}")
        print("\nè¯·åœ¨è™šæ‹Ÿç¯å¢ƒä¸­å®‰è£…ä¾èµ–ï¼š")
        print("pip install torch torchaudio numpy soundfile tqdm")
        sys.exit(1)
    print("ä¾èµ–åº“å¯¼å…¥æˆåŠŸ âœ“")
    print()

    # åŠ è½½ Silero VAD æ¨¡å‹
    print("-" * 60)
    print("åŠ è½½ Silero VAD æ¨¡å‹...")

    # è®¾ç½® Silero VAD æ¨¡å‹ä¸‹è½½ç›®å½•
    voxcpm_ft_path = Path(VOXCPM_FT_PROJECT_PATH)
    models_dir = voxcpm_ft_path / "models"
    models_dir.mkdir(parents=True, exist_ok=True)

    # è®¾ç½® torch.hub æ¨¡å‹ç›®å½•
    torch.hub.set_dir(str(models_dir))

    # åŒæ—¶è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ['TORCH_HOME'] = str(models_dir)

    print(f"VAD æ¨¡å‹ç›®å½•: {models_dir}")

    try:
        vad_model, utils = torch.hub.load(
            repo_or_dir='snakers4/silero-vad',
            model='silero_vad',
            force_reload=False
        )
        get_speech_timestamps, save_audio, read_audio, VADIterator, collect_chunks = utils
        print("Silero VAD æ¨¡å‹åŠ è½½å®Œæˆ âœ“")
        print()
    except Exception as e:
        print(f"âŒ Silero VAD æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        print("\næç¤ºï¼šé¦–æ¬¡ä½¿ç”¨ä¼šè‡ªåŠ¨ä¸‹è½½æ¨¡å‹åˆ°æŒ‡å®šç›®å½•")
        print(f"æ¨¡å‹ç›®å½•: {models_dir}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

    # è§£æ SRT
    print("-" * 60)
    print("è§£æ SRT æ–‡ä»¶...")
    segments = parse_srt_file(srt_path)
    print(f"ğŸ“ è§£æå®Œæˆ: {len(segments)} ä¸ªæ®µè½")
    print()

    # åˆ‡åˆ†éŸ³é¢‘
    print("-" * 60)
    print("å¼€å§‹åˆ‡åˆ†éŸ³é¢‘...")
    print()

    training_data, vad_warnings = segment_audio_with_vad(
        audio_path=audio_path,
        segments=segments,
        output_dir=data_dir,
        vad_model=vad_model,
        get_speech_timestamps=get_speech_timestamps,
        start_index=start_index,
        buffer_ms=BUFFER_MS,
        silence_ms=SILENCE_MS
    )

    print()

    # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
    if len(training_data) == 0:
        print("=" * 60)
        print("âš ï¸  è­¦å‘Šï¼šæœªæˆåŠŸåˆ‡åˆ†ä»»ä½•éŸ³é¢‘ç‰‡æ®µï¼")
        print("=" * 60)
        print("å¯èƒ½åŸå› ï¼š")
        print("  - SRT æ—¶é—´è½´å…¨éƒ¨æ— æ•ˆ")
        print("  - VAD æ£€æµ‹å…¨éƒ¨å¤±è´¥ä¸”æœç´¢åŒºåŸŸä¸ºç©º")
        print("  - éŸ³é¢‘æ–‡ä»¶æŸå")
        print()
        sys.exit(1)

    # ä¿å­˜/è¿½åŠ  JSONL è®­ç»ƒæ¸…å•
    print("-" * 60)
    print("ä¿å­˜è®­ç»ƒæ•°æ®æ¸…å•...")

    os.makedirs(data_dir, exist_ok=True)

    # è¿½åŠ æ¨¡å¼ï¼šæ‰“å¼€æ–‡ä»¶å¹¶è¿½åŠ 
    mode = 'a' if start_index > 0 else 'w'
    with open(jsonl_path, mode, encoding='utf-8') as f:
        for item in training_data:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')

    print(f"âœ… æ•°æ®å·²ä¿å­˜åˆ°: {jsonl_path}")
    print()

    # ç»Ÿè®¡ä¿¡æ¯
    total_duration = sum(item['duration'] for item in training_data)

    print("-" * 60)
    print("ğŸ“Š æœ¬æ¬¡å¤„ç†ç»Ÿè®¡:")
    print(f"   - ç‰‡æ®µæ•°: {len(training_data)}")
    print(f"   - æ€»æ—¶é•¿: {total_duration / 60:.2f} åˆ†é’Ÿ ({total_duration:.2f} ç§’)")
    print(f"   - å¹³å‡æ—¶é•¿: {total_duration / len(training_data):.2f} ç§’/ç‰‡æ®µ")
    print(f"   - èµ·å§‹åºå·: {start_index + 1:04d}")
    print(f"   - ç»“æŸåºå·: {start_index + len(training_data):04d}")

    # æ—¶é•¿åˆ†å¸ƒ
    durations = [item['duration'] for item in training_data]
    short = sum(1 for d in durations if d < 3)
    normal = sum(1 for d in durations if 3 <= d <= 10)
    long = sum(1 for d in durations if d > 10)

    print(f"\nğŸ“Š æ—¶é•¿åˆ†å¸ƒ:")
    print(f"   - < 3 ç§’: {short} ({short/len(durations)*100:.1f}%)")
    print(f"   - 3-10 ç§’: {normal} ({normal/len(durations)*100:.1f}%) âœ… æ¨è")
    print(f"   - > 10 ç§’: {long} ({long/len(durations)*100:.1f}%)")
    print()

    # VAD é€€å›è­¦å‘Š
    if vad_warnings:
        print("-" * 60)
        print(f"âš ï¸  VAD æ£€æµ‹é€€å›è­¦å‘Š ({len(vad_warnings)} æ¡)")
        print("-" * 60)
        print("ä»¥ä¸‹ç‰‡æ®µ VAD æœªæ£€æµ‹åˆ°è¯­éŸ³ï¼Œå·²é€€å›ä½¿ç”¨ SRT æ—¶é—´è½´ï¼š\n")
        for warning in vad_warnings:
            print(f"   - {warning}")
        print()

    print("=" * 60)
    print("ğŸ‰ å¤„ç†å®Œæˆï¼")
    print("=" * 60)
    print()
    print("ğŸ“‚ è¾“å‡ºæ–‡ä»¶:")
    print(f"   - éŸ³é¢‘ç‰‡æ®µ: {data_dir}")
    print(f"   - è®­ç»ƒæ¸…å•: {jsonl_path}")
    print()

def main() -> None:
    """ä¸»ç¨‹åºå…¥å£"""
    clear_screen()

    print("=" * 60)
    print("ğŸµ VoxCPM è®­ç»ƒæ•°æ®å‡†å¤‡ - åŸºäº SRT + Silero VAD ç²¾å‡†åˆ‡åˆ†")
    print("=" * 60)
    print()

    # è¿è¡ŒéŸ³é¢‘åˆ‡åˆ†ï¼ˆè‡ªåŠ¨å¤„ç†è™šæ‹Ÿç¯å¢ƒï¼‰
    run_segment_audio()

if __name__ == '__main__':
    main()
```

æ‰€æœ‰åˆ†å‰²å¥½çš„éŸ³é¢‘ç‰‡æ®µå°†è‡ªåŠ¨ä¿å­˜åœ¨ `/data` ç›®å½•ä¸‹ã€‚

---

## ä¸‰ã€æ¨¡å‹è®­ç»ƒ

### 3.1 ç¯å¢ƒé…ç½®

1. è®¿é—® [AutoDL å¹³å°](https://autodl.com/)
2. åœ¨åº”ç”¨å¸‚åœºæœç´¢ **VoxCPM-1.5-TTS-WEB-UI**
3. ç§Ÿç”¨ **RTX PRO 6000** GPU(æ¨èé…ç½®)ï¼ŒåŒæ—¶å¢åŠ æ•°æ®ç›˜çš„å®¹é‡ï¼Œé»˜è®¤çš„æ•°æ®ç›˜ä¸€èˆ¬æƒ…å†µä¸‹ä¸å¤Ÿç”¨ï¼Œå› ä¸ºè¦å­˜å‚¨è®­ç»ƒå¥½çš„æ¨¡å‹ï¼

è®­ç»ƒè¿‡ç¨‹ä¸­é‡åˆ°å¦‚ä¸‹çš„æŠ¥é”™ï¼Œå°±è¯´æ˜ç¡¬ç›˜å¡æ»¡äº†ï¼š
```
[train] step 980: loss/diff: 0.638490, loss/stop: 0.000001, lr: 0.000008, epoch: 19.454094, grad_norm: 0.882882, log interval: 4.73s
[train] step 990: loss/diff: 0.634882, loss/stop: 0.000001, lr: 0.000008, epoch: 19.652605, grad_norm: 0.967825, log interval: 4.65s
[train] step 1000: loss/diff: 0.618469, loss/stop: 0.000002, lr: 0.000008, epoch: 19.851117, grad_norm: 0.960394, log interval: 4.77s
Traceback (most recent call last):
File "/root/miniconda3/lib/python3.12/site-packages/torch/serialization.py", line 967, in save
_save(
File "/root/miniconda3/lib/python3.12/site-packages/torch/serialization.py", line 1268, in _save
zip_file.write_record(name, storage, num_bytes)
RuntimeError: [enforce fail at inline_container.cc:858] . PytorchStreamWriter failed writing file data/44: file write failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
File "/root/VoxCPM/scripts/train_voxcpm_finetune.py", line 360, in <module>
train(**yaml_args)
File "/root/miniconda3/lib/python3.12/site-packages/argbind/argbind.py", line 159, in cmd_func
return func(*cmd_args, **kwargs)
^^^^^^^^^^^^^^^^^^^^^^^^^
File "/root/VoxCPM/scripts/train_voxcpm_finetune.py", line 261, in train
save_checkpoint(model, optimizer, scheduler, save_dir, step, pretrained_path)
File "/root/VoxCPM/scripts/train_voxcpm_finetune.py", line 348, in save_checkpoint
torch.save(optimizer.state_dict(), folder / "optimizer.pth")
File "/root/miniconda3/lib/python3.12/site-packages/torch/serialization.py", line 966, in save
with _open_zipfile_writer(f) as opened_zipfile:
File "/root/miniconda3/lib/python3.12/site-packages/torch/serialization.py", line 798, in exit
self.file_like.write_end_of_file()
RuntimeError: [enforce fail at inline_container.cc:664] . unexpected pos 757021440 vs 757021328
```

### 3.2 æ•°æ®ä¸Šä¼ 

ä½¿ç”¨ **WinSCP** æˆ–å…¶ä»– SFTP å·¥å…·,å°† `/data` ç›®å½•ä¸‹çš„æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶ä¸Šä¼ è‡³:

```
/root/autodl-tmp/data/
```

### 3.3 é…ç½®æ–‡ä»¶ä¿®æ”¹

ç¼–è¾‘é…ç½®æ–‡ä»¶ `conf/voxcpm_v1.5/voxcpm_finetune_all.yaml`,ä¸»è¦ä¿®æ”¹:

- **æ•°æ®è·¯å¾„**:æŒ‡å‘ä¸Šä¼ çš„æ•°æ®ç›®å½•
- **è®­ç»ƒå‚æ•°**:batch sizeã€learning rateã€è®­ç»ƒæ­¥æ•°ç­‰
- **å…¶ä»–é…ç½®**:å¯å’¨è¯¢ AI åŠ©æ‰‹è·å–æœ€ä½³å®è·µå»ºè®®

ä»¥ä¸‹æ˜¯ä½¿ç”¨RTX PRO 6000 æ—¶è®­ç»ƒä½¿ç”¨çš„é…ç½®æ–‡ä»¶ï¼š
```
pretrained_path: /root/models/VoxCPM-1.5/
train_manifest: /root/autodl-tmp/data/train.jsonl
val_manifest: null
sample_rate: 44100
batch_size: 16
grad_accum_steps: 1  # Gradient accumulation steps, >1 can increase effective batch size without increasing memory
num_workers: 8
num_iters: 3000
log_interval: 10
valid_interval: 500
save_interval: 500
learning_rate: 0.00001 
weight_decay: 0.01
warmup_steps: 100
max_steps: 3000
max_batch_tokens: 8192  # Example: single batch can have at most 16k tokens, with batch_size=4, each sample can have at most 4096 tokens
save_path: /root/autodl-tmp/checkpoints/finetune_all
tensorboard: /root/autodl-tmp/logs/finetune_all
lambdas:
  loss/diff: 1.0
  loss/stop: 1.0
```
è®­ç»ƒå¥½çš„æ¨¡å‹ä¼šåœ¨/root/autodl-tmp/checkpoints/finetune_all
è®­ç»ƒçš„æ—¥å¿—ä¼šåœ¨/root/autodl-tmp/logs/finetune_all
å¯ä»¥æŠŠæ—¥å¿—å–‚ç»™geminiï¼Œè®©å®ƒé€šè¿‡æ—¥å¿—åˆ†æç†è®ºä¸Šå“ªä¸ªæ¨¡å‹æ•ˆæœæœ€å¥½ã€‚

æ³¨æ„ä¿®æ”¹è®­ç»ƒ.shçš„pyæ–‡ä»¶çš„åç§°ï¼Œä¸æ˜¯voxcpm_finetune_lora.yamlï¼Œè€Œæ˜¯voxcpm_finetune_all.yaml
```
cd /root/VoxCPM

python scripts/train_voxcpm_finetune.py --config_path conf/voxcpm_v1.5/voxcpm_finetune_all.yaml
echo '------------------------end.'
```
### 3.4 å¯åŠ¨è®­ç»ƒ

æŒ‰ç…§ AutoDL å¹³å°æä¾›çš„è®­ç»ƒè„šæœ¬æ‰§è¡Œå³å¯:

```
sh train.sh
```

---

## å››ã€æ³¨æ„äº‹é¡¹

- ç¡®ä¿ GPU æ˜¾å­˜å……è¶³(æ¨è 48GB ä»¥ä¸Š)
- å®šæœŸä¿å­˜è®­ç»ƒæ£€æŸ¥ç‚¹,é˜²æ­¢è®­ç»ƒä¸­æ–­
- ç›‘æ§è®­ç»ƒæ—¥å¿—,åŠæ—¶è°ƒæ•´è¶…å‚æ•°
- æ•°æ®è´¨é‡ç›´æ¥å½±å“æ¨¡å‹æ•ˆæœ,åŠ¡å¿…ä¸¥æ ¼æ‰§è¡Œæ•°æ®æ¸…æ´—æ ‡å‡†

---

## äº”ã€ç›¸å…³èµ„æº

- **Parakeet**:é«˜ç²¾åº¦ ASR å·¥å…·
- **Google AI Studio**:[https://aistudio.google.com](https://aistudio.google.com)
- **AutoDL å¹³å°**:[https://autodl.com](https://autodl.com)

---

*å‘å¸ƒäº:2026-01-13*
